# import numpy as np
# import pandas as pd
# import torch
# import pickle
# from deep_walmart import GRUModel  # Äáº£m báº£o báº¡n cÃ³ file model.py chá»©a GRUModel

# # === Thiáº¿t bá»‹ tÃ­nh toÃ¡n ===
# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# # === Load mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u ===
# trained_model = GRUModel(input_size=8)
# trained_model.load_state_dict(torch.load("model_checkpoints/best_model.pth", map_location=device))
# trained_model.to(device)
# trained_model.eval()

# # === Load scaler Ä‘Ã£ lÆ°u ===
# with open("model_checkpoints/input_scaler.pkl", "rb") as f:
#     input_scaler = pickle.load(f)
# with open("model_checkpoints/target_scaler.pkl", "rb") as f:
#     target_scaler = pickle.load(f)

# # === Äá»‹nh nghÄ©a cá»™t Ä‘áº·c trÆ°ng ===
# feature_cols = ['Weekly_Sales', 'Holiday_Flag', 'Temperature', 'Fuel_Price',
#                 'CPI', 'Unemployment', 'WeekOfYear', 'Month']
# input_features = ['Holiday_Flag', 'Temperature', 'Fuel_Price',
#                   'CPI', 'Unemployment', 'WeekOfYear', 'Month']
# weekly_sales_col = ['Weekly_Sales']

# # === Dá»¯ liá»‡u baseline cá»‘ Ä‘á»‹nh ===

# # === HÃ m kiá»ƒm tra áº£nh hÆ°á»Ÿng cá»§a 1 Ä‘áº·c trÆ°ng ===
# def test_feature_influence(changing_feature, values_to_test):
#     print(f"\nðŸ” Äang kiá»ƒm tra áº£nh hÆ°á»Ÿng cá»§a '{changing_feature}' Ä‘áº¿n dá»± Ä‘oÃ¡n doanh thu:")

#     predictions = []

#     # DÃ¹ng dá»¯ liá»‡u gá»‘c Ä‘Ã£ test thÃ nh cÃ´ng lÃ m baseline
#     base_input_df = pd.read_excel("test.xlsx")  # hoáº·c .read_excel náº¿u file excel

#     for val in values_to_test:
#         test_df = base_input_df.copy()
#         test_df[changing_feature] = val  # GÃ¡n giÃ¡ trá»‹ má»›i cho Ä‘áº·c trÆ°ng cáº§n kiá»ƒm tra

#         # Láº·p láº¡i xá»­ lÃ½ dá»¯ liá»‡u giá»‘ng nhÆ° lÃºc test
#         scaled_inputs_only = input_scaler.transform(test_df[input_features])
#         scaled_weekly_sales = target_scaler.transform(test_df[weekly_sales_col])
#         scaled_input = np.concatenate([scaled_weekly_sales, scaled_inputs_only], axis=1)

#         input_tensor = torch.tensor(scaled_input, dtype=torch.float32).unsqueeze(0).to(device)

#         with torch.no_grad():
#             y_pred_scaled = trained_model(input_tensor).cpu().numpy()
#             y_pred_real = target_scaler.inverse_transform(y_pred_scaled)[0, 0]

#         predictions.append((val, y_pred_real))

#     print(f"\nðŸ“Š Káº¿t quáº£:")
#     for val, pred in predictions:
#         print(f"   {changing_feature} = {val:>7.2f}  âžœ  ðŸ“ˆ Doanh thu dá»± Ä‘oÃ¡n: {pred:,.2f} VND")

# # === Thá»±c thi kiá»ƒm tra ===
# if __name__ == "__main__":
#     # CÃ¡c giÃ¡ trá»‹ Ä‘á»ƒ kiá»ƒm tra
#     temp_values = np.linspace(10, 40, 7)
#     fuel_values = np.linspace(16000, 24000, 5)
#     cpi_values = np.linspace(100, 150, 6)

#     test_feature_influence("Temperature", temp_values)
#     test_feature_influence("Fuel_Price", fuel_values)
#     test_feature_influence("CPI", cpi_values)


import numpy as np
import pandas as pd
import torch
import pickle
from deep_walmart import GRUModel  # Äáº£m báº£o báº¡n cÃ³ Ä‘Ãºng class GRUModel

# === Thiáº¿t bá»‹ tÃ­nh toÃ¡n ===
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# === Load mÃ´ hÃ¬nh tá»‘t nháº¥t Ä‘Ã£ lÆ°u ===
trained_model = GRUModel(input_size=8)
trained_model.load_state_dict(torch.load("model_checkpoints/best_model.pth", map_location=device))
trained_model.to(device)
trained_model.eval()

# === Load scaler Ä‘Ã£ lÆ°u ===
with open("model_checkpoints/input_scaler.pkl", "rb") as f:
    input_scaler = pickle.load(f)
with open("model_checkpoints/target_scaler.pkl", "rb") as f:
    target_scaler = pickle.load(f)

# === Äá»‹nh nghÄ©a cÃ¡c cá»™t Ä‘áº·c trÆ°ng ===
feature_cols = ['Weekly_Sales', 'Holiday_Flag', 'Temperature', 'Fuel_Price',
                'CPI', 'Unemployment', 'WeekOfYear', 'Month']
input_features = ['Holiday_Flag', 'Temperature', 'Fuel_Price',
                  'CPI', 'Unemployment', 'WeekOfYear', 'Month']
weekly_sales_col = ['Weekly_Sales']

# === HÃ m kiá»ƒm tra áº£nh hÆ°á»Ÿng cá»§a 1 Ä‘áº·c trÆ°ng ===
def test_feature_influence(changing_feature, values_to_test):
    print(f"\nðŸ” Äang kiá»ƒm tra áº£nh hÆ°á»Ÿng cá»§a '{changing_feature}' Ä‘áº¿n dá»± Ä‘oÃ¡n doanh thu:")

    predictions = []

    # ðŸ§¾ Load dá»¯ liá»‡u gá»‘c lÃ m baseline
    base_input_df = pd.read_excel("test.xlsx")  # Nhá»› Ä‘áº£m báº£o file nÃ y cÃ³ Ä‘Ãºng 10 dÃ²ng

    for val in values_to_test:
        test_df = base_input_df.copy()
        test_df[changing_feature] = val

        # ðŸ”„ Tiá»n xá»­ lÃ½ nhÆ° lÃºc training
        scaled_inputs_only = input_scaler.transform(test_df[input_features])
        scaled_weekly_sales = target_scaler.transform(test_df[weekly_sales_col])
        scaled_input = np.concatenate([scaled_weekly_sales, scaled_inputs_only], axis=1)

        # ðŸ“¦ ÄÆ°a vÃ o mÃ´ hÃ¬nh
        input_tensor = torch.tensor(scaled_input, dtype=torch.float32).unsqueeze(0).to(device)

        with torch.no_grad():
            y_pred_scaled = trained_model(input_tensor).cpu().numpy()
            y_pred_real = target_scaler.inverse_transform(y_pred_scaled)[0, 0]

        predictions.append((val, y_pred_real))

    # ðŸ–¨ï¸ In káº¿t quáº£
    print(f"\nðŸ“Š Káº¿t quáº£:")
    for val, pred in predictions:
        print(f"   {changing_feature} = {val:>7.2f}  âžœ  ðŸ“ˆ Doanh thu dá»± Ä‘oÃ¡n: {pred:,.2f} VND")

# === Cháº¡y kiá»ƒm tra ===
if __name__ == "__main__":
    # CÃ¡c giÃ¡ trá»‹ cáº§n thá»­ nghiá»‡m
    temp_values = np.linspace(10, 40, 7)
    fuel_values = np.linspace(16000, 24000, 5)
    cpi_values = np.linspace(100, 150, 6)

    test_feature_influence("Temperature", temp_values)
    test_feature_influence("Fuel_Price", fuel_values)
    test_feature_influence("CPI", cpi_values)
