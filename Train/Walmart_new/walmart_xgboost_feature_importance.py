import os
from pathlib import Path
from typing import List, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.inspection import permutation_importance
from xgboost import XGBRegressor


def find_dataset_path() -> Path:
    """
    TÃ¬m Ä‘Æ°á»ng dáº«n file walmart_processed_by_week.csv theo thá»© tá»± Æ°u tiÃªn:
    - CÃ¹ng dá»± Ã¡n: ../walmart_processed_by_week.csv (tá»« thÆ° má»¥c Walmart_new)
    - Tuyá»‡t Ä‘á»‘i: E:\\TrainAI\\Train\\walmart_processed_by_week.csv (mÃ´i trÆ°á»ng hiá»‡n táº¡i)
    - DÃ² theo Workspace (Ä‘i lÃªn 3 cáº¥p rá»“i ghÃ©p Ä‘Æ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i)
    """
    here = Path(__file__).resolve().parent
    candidates = [
        here.parent / "walmart_processed_by_week.csv",
        Path(r"E:\\TrainAI\\Train\\walmart_processed_by_week.csv"),
        Path(r"E:/TrainAI/Train/walmart_processed_by_week.csv"),
    ]

    # Thá»­ thÃªm: náº¿u Ä‘ang cháº¡y á»Ÿ mÃ´i trÆ°á»ng khÃ¡c, thá»­ láº§n theo repo root
    repo_root = here.parent.parent if here.name.lower() == "walmart_new" else here
    candidates.append(repo_root / "Train" / "walmart_processed_by_week.csv")

    for path in candidates:
        if path.exists():
            return path

    raise FileNotFoundError(
        "KhÃ´ng tÃ¬m tháº¥y file walmart_processed_by_week.csv. HÃ£y Ä‘áº·t file táº¡i 'Train/walmart_processed_by_week.csv' hoáº·c chá»‰nh sá»­a Ä‘Æ°á»ng dáº«n trong script."
    )


def select_available_features(df: pd.DataFrame) -> Tuple[List[str], str]:
    """
    Chá»n danh sÃ¡ch Ä‘áº·c trÆ°ng cÃ³ trong dataframe cho XGBoost.
    Target: 'Weekly_Sales'.
    """
    target = "Weekly_Sales"

    # Danh sÃ¡ch feature á»©ng viÃªn (Æ°u tiÃªn cÃ¡c cá»™t Ä‘Ã£ dÃ¹ng trong EDA/mÃ´ hÃ¬nh trÆ°á»›c)
    candidate_features = [
        "Holiday_Flag",
        "Temperature",
        "Fuel_Price",
        "CPI",
        "Unemployment",
        "Month",
        "WeekOfYear",
        "Year",
        # KhÃ´ng dÃ¹ng ID ná»™i bá»™ nhÆ° Store Ä‘á»ƒ chá»‰ kiá»ƒm tra yáº¿u tá»‘ bÃªn ngoÃ i
        # CÃ³ thá»ƒ má»Ÿ rá»™ng thÃªm náº¿u dataset cÃ³:
        "IsHoliday",
        "Dept",
        "Size",
        "Type",
    ]

    features = [col for col in candidate_features if col in df.columns]
    if not features:
        raise ValueError(
            "KhÃ´ng tÃ¬m tháº¥y cá»™t Ä‘áº·c trÆ°ng phÃ¹ há»£p. HÃ£y Ä‘áº£m báº£o cÃ¡c cá»™t nhÆ° Holiday_Flag, Temperature, Fuel_Price, CPI, Unemployment, Month, WeekOfYear, Year cÃ³ trong dá»¯ liá»‡u."
        )

    return features, target


def train_xgb_and_importance(df: pd.DataFrame, features: List[str], target: str, random_state: int = 42):
    # Loáº¡i bá» NA á»Ÿ cÃ¡c cá»™t cáº§n thiáº¿t
    df_clean = df.dropna(subset=features + [target]).copy()

    X_raw = df_clean[features]
    y = df_clean[target]

    # One-hot encode vá»›i cÃ¡c cá»™t khÃ´ng pháº£i sá»‘
    non_numeric_cols = [c for c in X_raw.columns if not np.issubdtype(X_raw[c].dtype, np.number)]
    if non_numeric_cols:
        X = pd.get_dummies(X_raw, columns=non_numeric_cols, drop_first=False)
    else:
        X = X_raw.copy()

    feature_names = X.columns.tolist()

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=random_state
    )

    # MÃ´ hÃ¬nh XGBoost Regression cÆ¡ báº£n, Ä‘á»§ máº¡nh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ importance
    model = XGBRegressor(
        n_estimators=600,
        max_depth=6,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        reg_lambda=1.0,
        random_state=random_state,
        objective="reg:squarederror",
        n_jobs=-1,
    )

    model.fit(X_train, y_train)

    # ÄÃ¡nh giÃ¡ nhanh
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    # Há»— trá»£ sklearn cÅ©: tá»± tÃ­nh RMSE tá»« MSE
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)

    print("=" * 60)
    print("ğŸ Hiá»‡u nÄƒng XGBoost (test set)")
    print(f"RÂ²: {r2:.4f} | RMSE: {rmse:,.2f} | MAE: {mae:,.2f}")

    # Feature importance tá»« mÃ´ hÃ¬nh (gain)
    booster = model.get_booster()
    # Map tÃªn cá»™t thÃ nh f0, f1 ... (phÃ²ng trÆ°á»ng há»£p booster tráº£ vá» fN)
    fmap = {f"f{idx}": name for idx, name in enumerate(feature_names)}
    gain_score = booster.get_score(importance_type="gain")
    # Chuyá»ƒn vá» tÃªn cá»™t tháº­t
    gain_series = pd.Series({fmap.get(k, k): v for k, v in gain_score.items()})
    gain_series = gain_series.reindex(feature_names).fillna(0.0).sort_values(ascending=False)

    print("\nğŸ”¥ Má»©c Ä‘á»™ quan trá»ng (Gain) tá»« XGBoost:")
    for name, val in gain_series.items():
        print(f"- {name}: {val:.6f}")

    # Permutation importance (á»•n Ä‘á»‹nh hÆ¡n, tá»‘n thá»i gian hÆ¡n chÃºt)
    print("\nâ³ TÃ­nh permutation importance...")
    perm = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=random_state, n_jobs=-1)
    perm_series = pd.Series(perm.importances_mean, index=feature_names).sort_values(ascending=False)

    print("\nğŸ§ª Permutation importance (mean decrease in score):")
    for name, val in perm_series.items():
        print(f"- {name}: {val:.6f}")

    return model, gain_series, perm_series, (r2, rmse, mae)


def save_importances(gain_series: pd.Series, perm_series: pd.Series, out_dir: Path):
    out_dir.mkdir(parents=True, exist_ok=True)

    gain_df = gain_series.reset_index()
    gain_df.columns = ["feature", "gain_importance"]
    gain_csv = out_dir / "xgb_feature_importance_gain.csv"
    gain_df.to_csv(gain_csv, index=False)

    perm_df = perm_series.reset_index()
    perm_df.columns = ["feature", "permutation_importance"]
    perm_csv = out_dir / "xgb_feature_importance_permutation.csv"
    perm_df.to_csv(perm_csv, index=False)

    print(f"\nğŸ’¾ ÄÃ£ lÆ°u CSV importance táº¡i:\n- {gain_csv}\n- {perm_csv}")

    # Váº½ biá»ƒu Ä‘á»“
    sns.set_theme(style="whitegrid")

    plt.figure(figsize=(8, max(3, len(gain_series) * 0.4)))
    gain_series.sort_values().plot(kind="barh", color="#1f77b4")
    plt.title("XGBoost Feature Importance (Gain)")
    plt.xlabel("Gain")
    plt.tight_layout()
    gain_png = out_dir / "xgb_feature_importance_gain.png"
    plt.savefig(gain_png, dpi=300, bbox_inches="tight")
    plt.close()

    plt.figure(figsize=(8, max(3, len(perm_series) * 0.4)))
    perm_series.sort_values().plot(kind="barh", color="#ff7f0e")
    plt.title("Permutation Importance (XGBoost)")
    plt.xlabel("Mean importance")
    plt.tight_layout()
    perm_png = out_dir / "xgb_feature_importance_permutation.png"
    plt.savefig(perm_png, dpi=300, bbox_inches="tight")
    plt.close()

    print(f"ğŸ“ˆ ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ táº¡i:\n- {gain_png}\n- {perm_png}")


def main():
    print("=" * 60)
    print("ğŸ§  TÃNH Má»¨C Äá»˜ LIÃŠN QUAN Äáº¶C TRÆ¯NG CHO DOANH THU WALMART (XGBoost)")
    print("=" * 60)

    # 1) Äá»c dá»¯ liá»‡u
    csv_path = find_dataset_path()
    print(f"ğŸ“„ Äang Ä‘á»c dá»¯ liá»‡u: {csv_path}")
    df = pd.read_csv(csv_path)

    # 2) Báº£o Ä‘áº£m Date lÃ  datetime & táº¡o feature thá»i gian náº¿u thiáº¿u
    if "Date" in df.columns:
        try:
            df["Date"] = pd.to_datetime(df["Date"])
        except Exception:
            pass

    if "Month" not in df.columns and "Date" in df.columns:
        df["Month"] = df["Date"].dt.month
    if "Year" not in df.columns and "Date" in df.columns:
        df["Year"] = df["Date"].dt.year
    if "WeekOfYear" not in df.columns and "Date" in df.columns:
        # isocalendar().week cho sá»‘ tuáº§n trong nÄƒm
        try:
            df["WeekOfYear"] = df["Date"].dt.isocalendar().week.astype(int)
        except Exception:
            pass

    # 3) Chá»n feature & target
    features, target = select_available_features(df)
    print("\nğŸ§¾ Sá»­ dá»¥ng cÃ¡c Ä‘áº·c trÆ°ng:")
    print(", ".join(features))
    print(f"ğŸ¯ Target: {target}")

    # 4) Train XGBoost vÃ  láº¥y importance
    model, gain_series, perm_series, metrics = train_xgb_and_importance(df, features, target)

    # 5) LÆ°u káº¿t quáº£
    out_dir = Path(__file__).resolve().parent
    save_importances(gain_series, perm_series, out_dir)

    print("\nâœ… HoÃ n táº¥t!")


if __name__ == "__main__":
    main()


