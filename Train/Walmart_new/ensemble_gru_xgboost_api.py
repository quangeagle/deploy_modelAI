# Ensemble GRU + XGBoost Sales Prediction API
# API k·∫øt h·ª£p GRU prediction + XGBoost adjustment

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional
import pickle
import warnings
import joblib
from datetime import datetime
import shap
warnings.filterwarnings('ignore')

# ========== 1. IMPROVED GRU MODEL CLASS ==========
class ImprovedGRUSalesPredictor(nn.Module):
    def __init__(self, input_size, hidden_size=128, num_layers=2, dropout=0.2):
        super(ImprovedGRUSalesPredictor, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # GRU layers v·ªõi attention
        self.gru = nn.GRU(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0,
            bidirectional=True
        )
        
        # Attention mechanism
        self.attention = nn.MultiheadAttention(
            embed_dim=hidden_size * 2,
            num_heads=8,
            dropout=dropout
        )
        
        # Additional layers
        self.fc1 = nn.Linear(hidden_size * 4, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)
        self.fc3 = nn.Linear(hidden_size // 2, 1)
        
        # Dropout layers
        self.dropout = nn.Dropout(dropout)
        self.layer_norm = nn.LayerNorm(hidden_size * 2)
        
        # Activation functions
        self.relu = nn.ReLU()
    
    def forward(self, x):
        # GRU processing
        gru_out, _ = self.gru(x)
        
        # Apply layer normalization
        gru_out = self.layer_norm(gru_out)
        
        # Self-attention mechanism
        gru_out = gru_out.transpose(0, 1)
        attn_out, _ = self.attention(gru_out, gru_out, gru_out)
        attn_out = attn_out.transpose(0, 1)
        
        # Global average pooling + max pooling
        avg_pool = torch.mean(attn_out, dim=1)
        max_pool, _ = torch.max(attn_out, dim=1)
        
        # Combine pooling results
        combined = torch.cat([avg_pool, max_pool], dim=1)
        
        # Fully connected layers
        out = self.fc1(combined)
        out = self.relu(out)
        out = self.dropout(out)
        
        out = self.fc2(out)
        out = self.relu(out)
        out = self.dropout(out)
        
        out = self.fc3(out)
        
        return out

# ========== 2. INPUT/OUTPUT MODELS ==========
class EnsemblePredictionRequest(BaseModel):
    """Input model cho Ensemble API"""
    sales_history: List[float]  # List 10 gi√° tr·ªã doanh thu tu·∫ßn tr∆∞·ªõc
    external_factors_current: Optional[dict] = None  # External factors tu·∫ßn hi·ªán t·∫°i
    external_factors_previous: Optional[dict] = None  # External factors tu·∫ßn tr∆∞·ªõc (ƒë·ªÉ t√≠nh change)

class EnsemblePredictionResponse(BaseModel):
    """Output model cho Ensemble API"""
    gru_prediction: float
    xgboost_adjustment: float
    final_prediction: float
    confidence_score: float
    input_sequence: List[float]
    external_factors_current: dict
    external_factors_previous: dict
    message: str
    ensemble_breakdown: dict
    adjustment_explanation: dict  # Gi·∫£i th√≠ch chi ti·∫øt adjustment v·ªõi SHAP

# ========== 3. MODEL LOADER ==========
class EnsembleModelLoader:
    def __init__(self):
        self.gru_model = None
        self.xgb_model = None
        self.sequence_scaler = None
        self.target_scaler = None
        self.feature_columns = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.load_models()
    
    def load_models(self):
        """Load c·∫£ GRU v√† XGBoost models"""
        try:
            print("üîÑ Loading Ensemble Models...")
            
            # 1. Load GRU Model
            print("üìä Loading Improved GRU model...")
            self.gru_model = ImprovedGRUSalesPredictor(input_size=1, hidden_size=128, num_layers=2, dropout=0.2)
            self.gru_model.load_state_dict(torch.load('improved_gru_model.pth', map_location=self.device))
            self.gru_model.to(self.device)
            self.gru_model.eval()
            
            # Load GRU scalers
            with open('improved_sequence_scaler.pkl', 'rb') as f:
                self.sequence_scaler = pickle.load(f)
            
            with open('improved_target_scaler.pkl', 'rb') as f:
                self.target_scaler = pickle.load(f)
            
            # 2. Load XGBoost Model
            print("üå≥ Loading XGBoost Adjustment model...")
            self.xgb_model = joblib.load('output_relative/xgb_model.pkl')
            
            # Load feature columns
            with open('output_relative/feature_columns.txt', 'r') as f:
                self.feature_columns = f.read().splitlines()
            
            print("‚úÖ Ensemble models loaded successfully!")
            print(f"üîß Device: {self.device}")
            print(f"üå≥ XGBoost features: {len(self.feature_columns)} features")
            
        except Exception as e:
            print(f"‚ùå Error loading models: {e}")
            raise e

# ========== 4. FEATURE PREPARATION ==========
def create_business_reason(feature_name: str, feature_value: float, shap_value: float, external_factors_current: dict, external_factors_previous: dict) -> str:
    """
    T·∫°o business reason d·ª±a tr√™n feature name v√† SHAP value
    """
    try:
        # Temperature change
        if 'Temperature_change' in feature_name:
            if shap_value > 0:
                return "Nhi·ªát ƒë·ªô tƒÉng ‚Üí Kh√°ch h√†ng tho·∫£i m√°i mua s·∫Øm ‚Üí TƒÉng doanh thu"
            else:
                return "Nhi·ªát ƒë·ªô gi·∫£m ‚Üí Kh√°ch h√†ng √≠t ra ngo√†i ‚Üí Gi·∫£m doanh thu"
        
        # Fuel Price change
        elif 'Fuel_Price_change' in feature_name:
            if shap_value > 0:
                return "Gi√° xƒÉng gi·∫£m ‚Üí Chi ph√≠ v·∫≠n chuy·ªÉn th·∫•p ‚Üí TƒÉng doanh thu"
            else:
                return "Gi√° xƒÉng tƒÉng ‚Üí Chi ph√≠ v·∫≠n chuy·ªÉn cao ‚Üí Gi·∫£m doanh thu"
        
        # CPI change
        elif 'CPI_change' in feature_name:
            if shap_value > 0:
                return "CPI gi·∫£m ‚Üí Gi·∫£m ph√°t ‚Üí S·ª©c mua tƒÉng ‚Üí TƒÉng doanh thu"
            else:
                return "CPI tƒÉng ‚Üí L·∫°m ph√°t cao ‚Üí S·ª©c mua gi·∫£m ‚Üí Gi·∫£m doanh thu"
        
        # Unemployment change
        elif 'Unemployment_change' in feature_name:
            if shap_value > 0:
                return "Th·∫•t nghi·ªáp gi·∫£m ‚Üí S·ª©c mua tƒÉng ‚Üí TƒÉng doanh thu"
            else:
                return "Th·∫•t nghi·ªáp tƒÉng ‚Üí S·ª©c mua gi·∫£m ‚Üí Gi·∫£m doanh thu"
        
        # Holiday Flag
        elif 'Holiday_Flag' in feature_name:
            if feature_value == 1:
                return "C√≥ ng√†y l·ªÖ ‚Üí Kh√°ch h√†ng mua s·∫Øm nhi·ªÅu ‚Üí TƒÉng doanh thu"
            else:
                return "Kh√¥ng c√≥ ng√†y l·ªÖ ‚Üí Doanh thu b√¨nh th∆∞·ªùng"
        
        # Month/Season
        elif 'Month' in feature_name:
            month = int(feature_value)
            if month in [11, 12]:
                return f"Th√°ng {month} - M√πa mua s·∫Øm cu·ªëi nƒÉm ‚Üí Doanh thu cao"
            elif month in [1, 2]:
                return f"Th√°ng {month} - Sau l·ªÖ, m√πa th·∫•p ƒëi·ªÉm ‚Üí Doanh thu th·∫•p"
            else:
                return f"Th√°ng {month} - M√πa b√¨nh th∆∞·ªùng ‚Üí Doanh thu ·ªïn ƒë·ªãnh"
        
        # Week of Year
        elif 'WeekOfYear' in feature_name:
            week = int(feature_value)
            if week in [50, 51, 52]:
                return f"Tu·∫ßn {week} - G·∫ßn Gi√°ng sinh ‚Üí Doanh thu cao"
            elif week in [1, 2, 3]:
                return f"Tu·∫ßn {week} - Sau l·ªÖ ‚Üí Doanh thu th·∫•p"
            else:
                return f"Tu·∫ßn {week} - Tu·∫ßn b√¨nh th∆∞·ªùng"
        
        # Weekend
        elif 'Is_Weekend' in feature_name:
            if feature_value == 1:
                return "Cu·ªëi tu·∫ßn ‚Üí Kh√°ch h√†ng c√≥ th·ªùi gian mua s·∫Øm ‚Üí TƒÉng doanh thu"
            else:
                return "Ng√†y th∆∞·ªùng ‚Üí Doanh thu b√¨nh th∆∞·ªùng"
        
        # Default
        else:
            if shap_value > 0:
                return f"{feature_name} c√≥ ·∫£nh h∆∞·ªüng t√≠ch c·ª±c ƒë·∫øn doanh thu"
            elif shap_value < 0:
                return f"{feature_name} c√≥ ·∫£nh h∆∞·ªüng ti√™u c·ª±c ƒë·∫øn doanh thu"
            else:
                return f"{feature_name} kh√¥ng ·∫£nh h∆∞·ªüng ƒë√°ng k·ªÉ"
                
    except Exception as e:
        return f"Kh√¥ng th·ªÉ t·∫°o business reason cho {feature_name}"

def create_adjustment_explanation_with_shap(model_loader, features_array: np.ndarray, external_factors_current: dict, external_factors_previous: dict, xgb_adjustment: float) -> dict:
    """
    T·∫°o gi·∫£i th√≠ch chi ti·∫øt v·ªÅ XGBoost adjustment s·ª≠ d·ª•ng SHAP values th·ª±c s·ª±
    """
    try:
        explanation = {
            "summary": "",
            "factor_analysis": {},
            "overall_impact": "",
            "business_logic": [],
            "shap_analysis": {},
            "contribution_breakdown": {}
        }
        
        # ========== STEP 1: T√çNH SHAP VALUES ==========
        print("üîç Calculating SHAP values...")
        
        # T·∫°o TreeExplainer cho XGBoost
        explainer = shap.TreeExplainer(model_loader.xgb_model)
        
        # T√≠nh SHAP values
        shap_values = explainer.shap_values(features_array)
        
        # L·∫•y feature names
        feature_names = model_loader.feature_columns
        
        # T·∫°o DataFrame ƒë·ªÉ d·ªÖ x·ª≠ l√Ω
        shap_df = pd.DataFrame({
            'feature': feature_names,
            'shap_value': shap_values[0],  # L·∫•y SHAP values cho sample ƒë·∫ßu ti√™n
            'feature_value': features_array[0]  # L·∫•y feature values
        })
        
        # S·∫Øp x·∫øp theo absolute SHAP values
        shap_df['abs_shap'] = abs(shap_df['shap_value'])
        shap_df = shap_df.sort_values('abs_shap', ascending=False)
        
        print(f"‚úÖ SHAP values calculated: {len(shap_df)} features")
        
        # ========== STEP 2: PH√ÇN T√çCH T·ª™NG FACTOR ==========
        factor_impacts = {}
        total_shap = abs(shap_df['shap_value'].sum())
        
        for _, row in shap_df.iterrows():
            feature_name = row['feature']
            shap_value = row['shap_value']
            feature_value = row['feature_value']
            
            # T√≠nh contribution percentage
            contribution_pct = (abs(shap_value) / total_shap * 100) if total_shap > 0 else 0
            
            # X√°c ƒë·ªãnh impact direction
            if shap_value > 0:
                impact = "positive"
                direction = "tƒÉng"
            elif shap_value < 0:
                impact = "negative"
                direction = "gi·∫£m"
            else:
                impact = "neutral"
                direction = "kh√¥ng ·∫£nh h∆∞·ªüng"
            
            # T·∫°o business reason d·ª±a tr√™n feature type
            business_reason = create_business_reason(feature_name, feature_value, shap_value, external_factors_current, external_factors_previous)
            
            factor_impacts[feature_name] = {
                "feature_value": feature_value,
                "shap_value": shap_value,
                "impact": impact,
                "direction": direction,
                "contribution_percentage": f"{contribution_pct:.1f}%",
                "business_reason": business_reason
            }
        
        # ========== STEP 3: T·∫†O SHAP ANALYSIS ==========
        shap_analysis = {
            "total_positive_contribution": float(shap_df[shap_df['shap_value'] > 0]['shap_value'].sum()),
            "total_negative_contribution": float(shap_df[shap_df['shap_value'] < 0]['shap_value'].sum()),
            "net_contribution": float(shap_df['shap_value'].sum()),
            "top_positive_features": shap_df[shap_df['shap_value'] > 0].head(3)[['feature', 'shap_value']].to_dict('records'),
            "top_negative_features": shap_df[shap_df['shap_value'] < 0].head(3)[['feature', 'shap_value']].to_dict('records'),
            "feature_ranking": shap_df[['feature', 'shap_value', 'abs_shap']].to_dict('records')
        }
        
        # ========== STEP 4: T·∫†O CONTRIBUTION BREAKDOWN ==========
        contribution_breakdown = {}
        for _, row in shap_df.iterrows():
            feature_name = row['feature']
            shap_value = row['shap_value']
            contribution_pct = (abs(shap_value) / total_shap * 100) if total_shap > 0 else 0
            
            if abs(shap_value) > 0.01:  # Ch·ªâ hi·ªÉn th·ªã features c√≥ ·∫£nh h∆∞·ªüng ƒë√°ng k·ªÉ
                contribution_breakdown[feature_name] = {
                    "shap_value": float(shap_value),
                    "contribution_percentage": f"{contribution_pct:.1f}%",
                    "direction": "tƒÉng" if shap_value > 0 else "gi·∫£m",
                    "interpretation": f"ƒê√≥ng g√≥p {contribution_pct:.1f}% v√†o adjustment ({'tƒÉng' if shap_value > 0 else 'gi·∫£m'} {abs(shap_value):,.0f})"
                }
        
        # ========== STEP 5: T·∫†O BUSINESS LOGIC ==========
        business_logic = []
        if xgb_adjustment > 0:
            business_logic.append(f"XGBoost d·ª± ƒëo√°n adjustment d∆∞∆°ng (+{xgb_adjustment:,.0f})")
            
            # T√¨m top positive contributors
            top_positive = shap_df[shap_df['shap_value'] > 0].head(3)
            if not top_positive.empty:
                top_features = top_positive['feature'].tolist()
                business_logic.append(f"Ch·ªß y·∫øu do: {', '.join(top_features)}")
            
            # T√¨m top negative contributors (n·∫øu c√≥)
            top_negative = shap_df[shap_df['shap_value'] < 0].head(3)
            if not top_negative.empty:
                top_features = top_negative['feature'].tolist()
                business_logic.append(f"M·∫∑c d√π c√≥: {', '.join(top_features)}")
        else:
            business_logic.append(f"XGBoost d·ª± ƒëo√°n adjustment √¢m ({xgb_adjustment:,.0f})")
            
            # T√¨m top negative contributors
            top_negative = shap_df[shap_df['shap_value'] < 0].head(3)
            if not top_negative.empty:
                top_features = top_negative['feature'].tolist()
                business_logic.append(f"Ch·ªß y·∫øu do: {', '.join(top_features)}")
            
            # T√¨m top positive contributors (n·∫øu c√≥)
            top_positive = shap_df[shap_df['shap_value'] > 0].head(3)
            if not top_positive.empty:
                top_features = top_positive['feature'].tolist()
                business_logic.append(f"M·∫∑c d√π c√≥: {', '.join(top_features)}")
        
        # ========== STEP 6: T·∫†O OVERALL IMPACT ==========
        positive_count = len(shap_df[shap_df['shap_value'] > 0])
        negative_count = len(shap_df[shap_df['shap_value'] < 0])
        
        if positive_count > negative_count:
            overall_impact = "T·ªïng th·ªÉ thu·∫≠n l·ª£i cho doanh thu"
        elif negative_count > positive_count:
            overall_impact = "T·ªïng th·ªÉ b·∫•t l·ª£i cho doanh thu"
        else:
            overall_impact = "T·ªïng th·ªÉ c√¢n b·∫±ng"
        
        # ========== STEP 7: T·∫†O SUMMARY ==========
        summary = f"XGBoost adjustment: {xgb_adjustment:,.0f} ({'tƒÉng' if xgb_adjustment > 0 else 'gi·∫£m'} doanh thu)"
        summary += f" | SHAP: +{shap_analysis['total_positive_contribution']:,.0f} / -{abs(shap_analysis['total_negative_contribution']):,.0f}"
        
        explanation = {
            "summary": summary,
            "factor_analysis": factor_impacts,
            "overall_impact": overall_impact,
            "business_logic": business_logic,
            "shap_analysis": shap_analysis,
            "contribution_breakdown": contribution_breakdown
        }
        
        return explanation
        
    except Exception as e:
        print(f"‚ùå Error creating SHAP explanation: {e}")
        return {
            "summary": "Kh√¥ng th·ªÉ t·∫°o SHAP explanation",
            "factor_analysis": {},
            "overall_impact": "Unknown",
            "business_logic": ["Error occurred"],
            "shap_analysis": {},
            "contribution_breakdown": {}
        }

def create_adjustment_explanation(external_factors_current: dict, external_factors_previous: dict, xgb_adjustment: float) -> dict:
    """
    T·∫°o gi·∫£i th√≠ch chi ti·∫øt v·ªÅ XGBoost adjustment v·ªõi contribution score
    """
    try:
        explanation = {
            "summary": "",
            "factor_analysis": {},
            "overall_impact": "",
            "business_logic": [],
            "contribution_breakdown": {}
        }
        
        # T√≠nh to√°n thay ƒë·ªïi v√† ph√¢n t√≠ch t·ª´ng factor
        factor_impacts = {}
        contribution_scores = {}
        
        # 1. Temperature Analysis
        if 'Temperature' in external_factors_previous and 'Temperature' in external_factors_current:
            temp_prev = external_factors_previous['Temperature']
            temp_curr = external_factors_current['Temperature']
            temp_change = ((temp_curr - temp_prev) / temp_prev * 100) if temp_prev != 0 else 0
            
            # T√≠nh contribution score cho Temperature
            if temp_change > 5:
                temp_contribution = min(25, abs(temp_change) * 0.5)  # Max 25% contribution
                factor_impacts['Temperature'] = {
                    "change": f"+{temp_change:.1f}%",
                    "impact": "positive",
                    "reason": "Nhi·ªát ƒë·ªô tƒÉng ‚Üí Kh√°ch h√†ng tho·∫£i m√°i mua s·∫Øm ‚Üí TƒÉng doanh thu",
                    "contribution_score": f"+{temp_contribution:.1f}%"
                }
                contribution_scores['Temperature'] = temp_contribution
            elif temp_change < -5:
                temp_contribution = -min(25, abs(temp_change) * 0.5)
                factor_impacts['Temperature'] = {
                    "change": f"{temp_change:.1f}%",
                    "impact": "negative", 
                    "reason": "Nhi·ªát ƒë·ªô gi·∫£m ‚Üí Kh√°ch h√†ng √≠t ra ngo√†i ‚Üí Gi·∫£m doanh thu",
                    "contribution_score": f"{temp_contribution:.1f}%"
                }
                contribution_scores['Temperature'] = temp_contribution
            else:
                factor_impacts['Temperature'] = {
                    "change": f"{temp_change:.1f}%",
                    "impact": "neutral",
                    "reason": "Nhi·ªát ƒë·ªô ·ªïn ƒë·ªãnh ‚Üí Kh√¥ng ·∫£nh h∆∞·ªüng ƒë√°ng k·ªÉ",
                    "contribution_score": "0%"
                }
                contribution_scores['Temperature'] = 0
        
        # 2. Fuel Price Analysis
        if 'Fuel_Price' in external_factors_previous and 'Fuel_Price' in external_factors_current:
            fuel_prev = external_factors_previous['Fuel_Price']
            fuel_curr = external_factors_current['Fuel_Price']
            fuel_change = ((fuel_curr - fuel_prev) / fuel_prev * 100) if fuel_prev != 0 else 0
            
            if fuel_change > 10:
                fuel_contribution = -min(30, abs(fuel_change) * 0.8)  # Max 30% negative contribution
                factor_impacts['Fuel_Price'] = {
                    "change": f"+{fuel_change:.1f}%",
                    "impact": "negative",
                    "reason": "Gi√° xƒÉng tƒÉng m·∫°nh ‚Üí Chi ph√≠ v·∫≠n chuy·ªÉn cao ‚Üí Gi·∫£m doanh thu",
                    "contribution_score": f"{fuel_contribution:.1f}%"
                }
                contribution_scores['Fuel_Price'] = fuel_contribution
            elif fuel_change < -5:
                fuel_contribution = min(20, abs(fuel_change) * 0.6)
                factor_impacts['Fuel_Price'] = {
                    "change": f"{fuel_change:.1f}%",
                    "impact": "positive",
                    "reason": "Gi√° xƒÉng gi·∫£m ‚Üí Chi ph√≠ v·∫≠n chuy·ªÉn th·∫•p ‚Üí TƒÉng doanh thu",
                    "contribution_score": f"+{fuel_contribution:.1f}%"
                }
                contribution_scores['Fuel_Price'] = fuel_contribution
            else:
                factor_impacts['Fuel_Price'] = {
                    "change": f"{fuel_change:.1f}%",
                    "impact": "neutral",
                    "reason": "Gi√° xƒÉng ·ªïn ƒë·ªãnh ‚Üí Kh√¥ng ·∫£nh h∆∞·ªüng ƒë√°ng k·ªÉ",
                    "contribution_score": "0%"
                }
                contribution_scores['Fuel_Price'] = 0
        
        # 3. CPI Analysis
        if 'CPI' in external_factors_previous and 'CPI' in external_factors_current:
            cpi_prev = external_factors_previous['CPI']
            cpi_curr = external_factors_current['CPI']
            cpi_change = ((cpi_curr - cpi_prev) / cpi_prev * 100) if cpi_prev != 0 else 0
            
            if cpi_change > 3:
                cpi_contribution = -min(25, abs(cpi_change) * 2.0)  # CPI c√≥ ·∫£nh h∆∞·ªüng m·∫°nh
                factor_impacts['CPI'] = {
                    "change": f"+{cpi_change:.1f}%",
                    "impact": "negative",
                    "reason": "CPI tƒÉng ‚Üí L·∫°m ph√°t cao ‚Üí S·ª©c mua gi·∫£m ‚Üí Gi·∫£m doanh thu",
                    "contribution_score": f"{cpi_contribution:.1f}%"
                }
                contribution_scores['CPI'] = cpi_contribution
            elif cpi_change < -2:
                cpi_contribution = min(20, abs(cpi_change) * 1.5)
                factor_impacts['CPI'] = {
                    "change": f"{cpi_change:.1f}%",
                    "impact": "positive",
                    "reason": "CPI gi·∫£m ‚Üí Gi·∫£m ph√°t ‚Üí S·ª©c mua tƒÉng ‚Üí TƒÉng doanh thu",
                    "contribution_score": f"+{cpi_contribution:.1f}%"
                }
                contribution_scores['CPI'] = cpi_contribution
            else:
                factor_impacts['CPI'] = {
                    "change": f"{cpi_change:.1f}%",
                    "impact": "neutral",
                    "reason": "CPI ·ªïn ƒë·ªãnh ‚Üí Kh√¥ng ·∫£nh h∆∞·ªüng ƒë√°ng k·ªÉ",
                    "contribution_score": "0%"
                }
                contribution_scores['CPI'] = 0
        
        # 4. Unemployment Analysis
        if 'Unemployment' in external_factors_previous and 'Unemployment' in external_factors_current:
            unemp_prev = external_factors_previous['Unemployment']
            unemp_curr = external_factors_current['Unemployment']
            unemp_change = ((unemp_curr - unemp_prev) / unemp_prev * 100) if unemp_prev != 0 else 0
            
            if unemp_change > 20:
                unemp_contribution = -min(35, abs(unemp_change) * 0.7)  # Unemployment c√≥ ·∫£nh h∆∞·ªüng r·∫•t m·∫°nh
                factor_impacts['Unemployment'] = {
                    "change": f"+{unemp_change:.1f}%",
                    "impact": "negative",
                    "reason": "Th·∫•t nghi·ªáp tƒÉng m·∫°nh ‚Üí S·ª©c mua gi·∫£m ‚Üí Gi·∫£m doanh thu",
                    "contribution_score": f"{unemp_contribution:.1f}%"
                }
                contribution_scores['Unemployment'] = unemp_contribution
            elif unemp_change < -10:
                unemp_contribution = min(30, abs(unemp_change) * 0.8)
                factor_impacts['Unemployment'] = {
                    "change": f"{unemp_change:.1f}%",
                    "impact": "positive",
                    "reason": "Th·∫•t nghi·ªáp gi·∫£m ‚Üí S·ª©c mua tƒÉng ‚Üí TƒÉng doanh thu",
                    "contribution_score": f"+{unemp_contribution:.1f}%"
                }
                contribution_scores['Unemployment'] = unemp_contribution
            else:
                factor_impacts['Unemployment'] = {
                    "change": f"{unemp_change:.1f}%",
                    "impact": "neutral",
                    "reason": "Th·∫•t nghi·ªáp ·ªïn ƒë·ªãnh ‚Üí Kh√¥ng ·∫£nh h∆∞·ªüng ƒë√°ng k·ªÉ",
                    "contribution_score": "0%"
                }
                contribution_scores['Unemployment'] = 0
        
        # 5. Holiday Analysis
        if 'Holiday_Flag' in external_factors_current:
            holiday_flag = external_factors_current['Holiday_Flag']
            if holiday_flag == 1:
                holiday_contribution = 15  # Holiday c√≥ ·∫£nh h∆∞·ªüng c·ªë ƒë·ªãnh
                factor_impacts['Holiday_Flag'] = {
                    "change": "C√≥ ng√†y l·ªÖ",
                    "impact": "positive",
                    "reason": "Ng√†y l·ªÖ ‚Üí Kh√°ch h√†ng mua s·∫Øm nhi·ªÅu ‚Üí TƒÉng doanh thu",
                    "contribution_score": f"+{holiday_contribution:.1f}%"
                }
                contribution_scores['Holiday_Flag'] = holiday_contribution
            else:
                factor_impacts['Holiday_Flag'] = {
                    "change": "Kh√¥ng c√≥ l·ªÖ",
                    "impact": "neutral",
                    "reason": "Kh√¥ng c√≥ ng√†y l·ªÖ ‚Üí Doanh thu b√¨nh th∆∞·ªùng",
                    "contribution_score": "0%"
                }
                contribution_scores['Holiday_Flag'] = 0
        
        # 6. Seasonal Analysis
        if 'Month' in external_factors_current:
            month = external_factors_current['Month']
            if month in [11, 12]:  # Th√°ng 11-12
                season_contribution = 20  # M√πa mua s·∫Øm cu·ªëi nƒÉm
                factor_impacts['Season'] = {
                    "change": f"Th√°ng {month}",
                    "impact": "positive",
                    "reason": "M√πa mua s·∫Øm cu·ªëi nƒÉm ‚Üí Doanh thu cao",
                    "contribution_score": f"+{season_contribution:.1f}%"
                }
                contribution_scores['Season'] = season_contribution
            elif month in [1, 2]:  # Th√°ng 1-2
                season_contribution = -15  # Sau l·ªÖ, m√πa th·∫•p ƒëi·ªÉm
                factor_impacts['Season'] = {
                    "change": f"Th√°ng {month}",
                    "impact": "negative",
                    "reason": "Sau l·ªÖ, m√πa th·∫•p ƒëi·ªÉm ‚Üí Doanh thu th·∫•p",
                    "contribution_score": f"{season_contribution:.1f}%"
                }
                contribution_scores['Season'] = season_contribution
            else:
                factor_impacts['Season'] = {
                    "change": f"Th√°ng {month}",
                    "impact": "neutral",
                    "reason": "M√πa b√¨nh th∆∞·ªùng ‚Üí Doanh thu ·ªïn ƒë·ªãnh",
                    "contribution_score": "0%"
                }
                contribution_scores['Season'] = 0
        
        # T√≠nh t·ªïng contribution v√† normalize
        total_contribution = sum(contribution_scores.values())
        if total_contribution != 0:
            # Normalize ƒë·ªÉ t·ªïng = 100% (ho·∫∑c -100% n·∫øu √¢m)
            normalization_factor = 100 / abs(total_contribution)
            normalized_contributions = {k: v * normalization_factor for k, v in contribution_scores.items()}
        else:
            normalized_contributions = contribution_scores
        
        # T·∫°o contribution breakdown
        contribution_breakdown = {}
        for factor, score in normalized_contributions.items():
            if score != 0:
                contribution_breakdown[factor] = {
                    "raw_score": f"{score:.1f}%",
                    "interpretation": f"ƒê√≥ng g√≥p {abs(score):.1f}% v√†o adjustment",
                    "direction": "tƒÉng" if score > 0 else "gi·∫£m"
                }
        
        # T·∫°o summary v√† overall impact
        positive_factors = [k for k, v in factor_impacts.items() if v['impact'] == 'positive']
        negative_factors = [k for k, v in factor_impacts.items() if v['impact'] == 'negative']
        neutral_factors = [k for k, v in factor_impacts.items() if v['impact'] == 'neutral']
        
        # T·∫°o business logic
        business_logic = []
        if xgb_adjustment > 0:
            business_logic.append(f"XGBoost d·ª± ƒëo√°n adjustment d∆∞∆°ng (+{xgb_adjustment:,.0f})")
            if positive_factors:
                business_logic.append(f"Ch·ªß y·∫øu do: {', '.join(positive_factors)}")
            if negative_factors:
                business_logic.append(f"M·∫∑c d√π c√≥: {', '.join(negative_factors)}")
        else:
            business_logic.append(f"XGBoost d·ª± ƒëo√°n adjustment √¢m ({xgb_adjustment:,.0f})")
            if negative_factors:
                business_logic.append(f"Ch·ªß y·∫øu do: {', '.join(negative_factors)}")
            if positive_factors:
                business_logic.append(f"M·∫∑c d√π c√≥: {', '.join(positive_factors)}")
        
        # T·∫°o overall impact
        if len(positive_factors) > len(negative_factors):
            overall_impact = "T·ªïng th·ªÉ thu·∫≠n l·ª£i cho doanh thu"
        elif len(negative_factors) > len(positive_factors):
            overall_impact = "T·ªïng th·ªÉ b·∫•t l·ª£i cho doanh thu"
        else:
            overall_impact = "T·ªïng th·ªÉ c√¢n b·∫±ng"
        
        explanation = {
            "summary": f"XGBoost adjustment: {xgb_adjustment:,.0f} ({'tƒÉng' if xgb_adjustment > 0 else 'gi·∫£m'} doanh thu)",
            "factor_analysis": factor_impacts,
            "overall_impact": overall_impact,
            "business_logic": business_logic,
            "contribution_breakdown": contribution_breakdown
        }
        
        return explanation
        
    except Exception as e:
        print(f"‚ùå Error creating adjustment explanation: {e}")
        return {
            "summary": "Kh√¥ng th·ªÉ t·∫°o gi·∫£i th√≠ch",
            "factor_analysis": {},
            "overall_impact": "Unknown",
            "business_logic": ["Error occurred"]
        }

def prepare_external_features_with_changes(external_factors_current: dict, external_factors_previous: dict, feature_columns: List[str]) -> np.ndarray:
    """
    Chu·∫©n b·ªã external features cho XGBoost v·ªõi t√≠nh to√°n thay ƒë·ªïi t∆∞∆°ng ƒë·ªëi
    """
    try:
        # T·∫°o DataFrame v·ªõi external factors hi·ªán t·∫°i
        features_df = pd.DataFrame([external_factors_current])
        
        # T√≠nh to√°n thay ƒë·ªïi t∆∞∆°ng ƒë·ªëi n·∫øu c√≥ d·ªØ li·ªáu tu·∫ßn tr∆∞·ªõc
        if external_factors_previous:
            for col in ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']:
                if col in external_factors_previous and col in external_factors_current:
                    prev_val = external_factors_previous[col]
                    curr_val = external_factors_current[col]
                    
                    if prev_val != 0:  # Tr√°nh chia cho 0
                        change_pct = ((curr_val - prev_val) / prev_val) * 100
                        features_df[f'{col}_change'] = change_pct
                    else:
                        features_df[f'{col}_change'] = 0.0
                else:
                    features_df[f'{col}_change'] = 0.0
        else:
            # N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu tu·∫ßn tr∆∞·ªõc, set change = 0
            for col in ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']:
                features_df[f'{col}_change'] = 0.0
        
        # ƒê·∫£m b·∫£o t·∫•t c·∫£ required features c√≥ m·∫∑t
        for col in feature_columns:
            if col not in features_df.columns:
                # Set default values cho missing features
                if 'change' in col:
                    features_df[col] = 0.0  # No change
                elif col in ['Holiday_Flag', 'Is_Weekend']:
                    features_df[col] = 0  # Not holiday/weekend
                elif col in ['Month', 'WeekOfYear', 'Year', 'DayOfWeek']:
                    # Set current date values
                    now = datetime.now()
                    if col == 'Month':
                        features_df[col] = now.month
                    elif col == 'WeekOfYear':
                        features_df[col] = now.isocalendar()[1]
                    elif col == 'Year':
                        features_df[col] = now.year
                    elif col == 'DayOfWeek':
                        features_df[col] = now.weekday()
                else:
                    features_df[col] = 0.0
        
        # Reorder columns theo th·ª© t·ª± feature_columns
        features_df = features_df[feature_columns]
        
        # Convert to numpy array
        features_array = features_df.values.astype(np.float32)
        
        print(f"‚úÖ Prepared features with changes: {features_array.shape}")
        print(f"üìä Features: {list(features_df.columns)}")
        return features_array
        
    except Exception as e:
        print(f"‚ùå Error preparing features: {e}")
        raise e

# ========== 5. ENSEMBLE PREDICTION FUNCTION ==========
def predict_sales_ensemble(model_loader, sales_history: List[float], external_factors_current: Optional[dict] = None, external_factors_previous: Optional[dict] = None) -> dict:
    """
    D·ª± ƒëo√°n doanh thu v·ªõi ensemble GRU + XGBoost
    """
    try:
        # Validate input
        if len(sales_history) != 10:
            raise ValueError("C·∫ßn ƒë√∫ng 10 gi√° tr·ªã doanh thu tu·∫ßn tr∆∞·ªõc")
        
        print("üîÑ Starting ensemble prediction...")
        
        # ========== STEP 1: GRU PREDICTION ==========
        print("üìä Step 1: GRU prediction...")
        
        # Convert to numpy array
        sequence = np.array(sales_history, dtype=np.float32)
        
        # Reshape to (1, 10, 1) for batch processing
        sequence = sequence.reshape(1, -1, 1)
        
        # Scale sequence
        sequence_scaled = model_loader.sequence_scaler.transform(sequence.reshape(-1, 1)).reshape(sequence.shape)
        
        # Convert to tensor
        sequence_tensor = torch.tensor(sequence_scaled, dtype=torch.float32).to(model_loader.device)
        
        # GRU Predict
        with torch.no_grad():
            prediction_scaled = model_loader.gru_model(sequence_tensor)
            gru_prediction = model_loader.target_scaler.inverse_transform(prediction_scaled.cpu().numpy().reshape(-1, 1))
        
        gru_prediction = float(gru_prediction[0, 0])
        print(f"‚úÖ GRU prediction: {gru_prediction:,.2f}")
        
        # ========== STEP 2: XGBOOST ADJUSTMENT ==========
        print("üå≥ Step 2: XGBoost adjustment...")
        
        # Prepare external features
        if external_factors_current is None:
            # Default external factors hi·ªán t·∫°i
            external_factors_current = {
                'Temperature': 20.0,
                'Fuel_Price': 3.50,
                'CPI': 200.0,
                'Unemployment': 5.0,
                'Holiday_Flag': 0,
                'Month': datetime.now().month,
                'WeekOfYear': datetime.now().isocalendar()[1],
                'Year': datetime.now().year,
                'DayOfWeek': datetime.now().weekday(),
                'Is_Weekend': 1 if datetime.now().weekday() >= 5 else 0
            }
        
        if external_factors_previous is None:
            # Default external factors tu·∫ßn tr∆∞·ªõc (ƒë·ªÉ t√≠nh change)
            external_factors_previous = {
                'Temperature': 20.0,
                'Fuel_Price': 3.50,
                'CPI': 200.0,
                'Unemployment': 5.0
            }
        
        # Prepare features for XGBoost v·ªõi t√≠nh to√°n change
        features_array = prepare_external_features_with_changes(external_factors_current, external_factors_previous, model_loader.feature_columns)
        
        # XGBoost predict adjustment
        xgb_adjustment = model_loader.xgb_model.predict(features_array)[0]
        print(f"‚úÖ XGBoost adjustment: {xgb_adjustment:,.2f}")
        
        # ========== STEP 3: ENSEMBLE FINAL PREDICTION ==========
        print("üöÄ Step 3: Ensemble final prediction...")
        
        final_prediction = gru_prediction + xgb_adjustment
        print(f"‚úÖ Final prediction: {final_prediction:,.2f}")
        
        # ========== STEP 4: CALCULATE CONFIDENCE ==========
        # Base confidence t·ª´ GRU
        input_std = np.std(sales_history)
        input_mean = np.mean(sales_history)
        cv = input_std / input_mean if input_mean > 0 else 0
        base_confidence = max(0.5, 1 - cv)
        
        # Adjust confidence based on adjustment magnitude
        adjustment_ratio = abs(xgb_adjustment) / gru_prediction if gru_prediction > 0 else 0
        if adjustment_ratio > 0.3:  # Large adjustment
            confidence = base_confidence * 0.7
        elif adjustment_ratio > 0.1:  # Medium adjustment
            confidence = base_confidence * 0.85
        else:  # Small adjustment
            confidence = base_confidence
        
        confidence = min(0.95, max(0.3, confidence))  # Clamp between 0.3 and 0.95
        
        # ========== STEP 5: PREPARE RESPONSE ==========
        message = f"Ensemble prediction successful - GRU: {gru_prediction:,.0f}, XGBoost adjustment: {xgb_adjustment:,.0f}"
        
        ensemble_breakdown = {
            "gru_contribution": float(gru_prediction),
            "xgboost_contribution": float(xgb_adjustment),
            "adjustment_ratio": float(adjustment_ratio),
            "prediction_method": "GRU_base + XGBoost_adjustment"
        }
        
        # ========== STEP 6: CREATE ADJUSTMENT EXPLANATION ==========
        adjustment_explanation = create_adjustment_explanation_with_shap(model_loader, features_array, external_factors_current, external_factors_previous, xgb_adjustment)
        
        return {
            "gru_prediction": gru_prediction,
            "xgboost_adjustment": xgb_adjustment,
            "final_prediction": final_prediction,
            "confidence_score": confidence,
            "input_sequence": sales_history,
            "external_factors_current": external_factors_current,
            "external_factors_previous": external_factors_previous,
            "message": message,
            "ensemble_breakdown": ensemble_breakdown,
            "adjustment_explanation": adjustment_explanation
        }
        
    except Exception as e:
        print(f"‚ùå Error in ensemble prediction: {e}")
        raise HTTPException(status_code=400, detail=f"L·ªói d·ª± ƒëo√°n ensemble: {str(e)}")

# ========== 6. FASTAPI APP ==========
app = FastAPI(
    title="Ensemble GRU + XGBoost Sales Prediction API",
    description="API k·∫øt h·ª£p GRU prediction + XGBoost adjustment cho doanh thu Walmart",
    version="1.0.0"
)

# Load models khi kh·ªüi ƒë·ªông
print("üöÄ Initializing Ensemble API...")
model_loader = EnsembleModelLoader()

@app.get("/")
def read_root():
    """Root endpoint"""
    return {
        "message": "Ensemble GRU + XGBoost Sales Prediction API",
        "version": "1.0.0",
        "models": {
            "gru": "Improved GRU (Bidirectional + Attention)",
            "xgboost": "XGBoost Adjustment Model"
        },
        "architecture": "GRU_base + XGBoost_adjustment = Final_Prediction",
        "input_features": {
            "gru": "10 tu·∫ßn doanh thu tr∆∞·ªõc",
            "xgboost": "External factors (temperature, fuel price, etc.)"
        },
        "output": "Doanh thu tu·∫ßn ti·∫øp theo v·ªõi ensemble prediction"
    }

@app.get("/health")
def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "gru_loaded": model_loader.gru_model is not None,
        "xgboost_loaded": model_loader.xgb_model is not None,
        "device": str(model_loader.device),
        "feature_columns": len(model_loader.feature_columns) if model_loader.feature_columns else 0
    }

@app.post("/predict", response_model=EnsemblePredictionResponse)
def predict_sales_ensemble_endpoint(request: EnsemblePredictionRequest):
    """
    D·ª± ƒëo√°n doanh thu tu·∫ßn ti·∫øp theo v·ªõi ensemble GRU + XGBoost
    
    **Input:**
    - sales_history: List 10 gi√° tr·ªã doanh thu tu·∫ßn tr∆∞·ªõc
    - external_factors: Optional dict v·ªõi external factors
    
    **Output:**
    - gru_prediction: D·ª± ƒëo√°n t·ª´ GRU model
    - xgboost_adjustment: ƒêi·ªÅu ch·ªânh t·ª´ XGBoost
    - final_prediction: K·∫øt qu·∫£ cu·ªëi c√πng
    - confidence_score: ƒê·ªô tin c·∫≠y
    """
    try:
        result = predict_sales_ensemble(model_loader, request.sales_history, request.external_factors_current, request.external_factors_previous)
        return EnsemblePredictionResponse(**result)
    
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/model-info")
def get_model_info():
    """Th√¥ng tin v·ªÅ ensemble model"""
    return {
        "ensemble_type": "GRU + XGBoost",
        "architecture": {
            "gru": {
                "type": "Improved GRU",
                "input_size": 1,
                "hidden_size": 128,
                "num_layers": 2,
                "bidirectional": True,
                "attention": True
            },
            "xgboost": {
                "type": "XGBoost Adjustment",
                "features": len(model_loader.feature_columns) if model_loader.feature_columns else 0,
                "feature_type": "Relative Changes"
            }
        },
        "prediction_flow": {
            "step1": "GRU predicts base sales from 10-week history",
            "step2": "XGBoost predicts adjustment from external factors",
            "step3": "Final = GRU_pred + XGBoost_adjustment"
        },
        "lookback_period": 10,
        "external_factors": model_loader.feature_columns if model_loader.feature_columns else [],
        "description": "Ensemble model k·∫øt h·ª£p GRU base prediction v√† XGBoost adjustment"
    }

@app.get("/example")
def get_example():
    """V√≠ d·ª• input cho Ensemble API"""
    return {
        "example_request": {
            "sales_history": [1000000, 1050000, 1100000, 1150000, 1200000, 1250000, 1300000, 1350000, 1400000, 1450000],
            "external_factors_current": {
                "Temperature": 28.0,
                "Fuel_Price": 3.60,
                "CPI": 203.0,
                "Unemployment": 4.95,
                "Holiday_Flag": 1,
                "Month": 12,
                "WeekOfYear": 50,
                "Year": 2024,
                "DayOfWeek": 2,
                "Is_Weekend": 0
            },
            "external_factors_previous": {
                "Temperature": 25.0,
                "Fuel_Price": 3.50,
                "CPI": 200.0,
                "Unemployment": 5.0
            }
        },
        "expected_output": {
            "gru_prediction": "Base prediction from GRU",
            "xgboost_adjustment": "Adjustment from external factors",
            "final_prediction": "GRU_pred + XGBoost_adjustment"
        },
        "note": "API s·∫Ω t·ª± ƒë·ªông t√≠nh Temperature_change, Fuel_Price_change, etc. t·ª´ external_factors_previous v√† external_factors_current"
    }

@app.get("/test-ensemble")
def test_ensemble_workflow():
    """Test lu·ªìng ho·∫°t ƒë·ªông ensemble v·ªõi c√°c scenarios kh√°c nhau"""
    
    test_scenarios = {
        "increasing_trend": {
            "sales_history": [1000000, 1050000, 1100000, 1150000, 1200000, 1250000, 1300000, 1350000, 1400000, 1450000],
            "external_factors_current": {
                "Temperature": 28.0,
                "Fuel_Price": 3.60,
                "CPI": 203.0,
                "Unemployment": 4.95,
                "Holiday_Flag": 1,
                "Month": 12,
                "WeekOfYear": 50,
                "Year": 2024,
                "DayOfWeek": 2,
                "Is_Weekend": 0
            },
            "external_factors_previous": {
                "Temperature": 25.0,
                "Fuel_Price": 3.50,
                "CPI": 200.0,
                "Unemployment": 5.0
            }
        },
        "decreasing_trend": {
            "sales_history": [1500000, 1450000, 1400000, 1350000, 1300000, 1250000, 1200000, 1150000, 1100000, 1050000],
            "external_factors_current": {
                "Temperature": 17.0,
                "Fuel_Price": 3.78,
                "CPI": 198.0,
                "Unemployment": 5.1,
                "Holiday_Flag": 0,
                "Month": 1,
                "WeekOfYear": 3,
                "Year": 2024,
                "DayOfWeek": 1,
                "Is_Weekend": 0
            },
            "external_factors_previous": {
                "Temperature": 20.0,
                "Fuel_Price": 3.50,
                "CPI": 200.0,
                "Unemployment": 5.0
            }
        },
        "stable_trend": {
            "sales_history": [1200000, 1200000, 1200000, 1200000, 1200000, 1200000, 1200000, 1200000, 1200000, 1200000],
            "external_factors_current": {
                "Temperature": 20.0,
                "Fuel_Price": 3.50,
                "CPI": 200.0,
                "Unemployment": 5.0,
                "Holiday_Flag": 0,
                "Month": 6,
                "WeekOfYear": 25,
                "Year": 2024,
                "DayOfWeek": 3,
                "Is_Weekend": 0
            },
            "external_factors_previous": {
                "Temperature": 20.0,
                "Fuel_Price": 3.50,
                "CPI": 200.0,
                "Unemployment": 5.0
            }
        }
    }
    
    results = {}
    for scenario_name, test_data in test_scenarios.items():
        try:
            print(f"\nüß™ Testing scenario: {scenario_name}")
            result = predict_sales_ensemble(model_loader, test_data["sales_history"], test_data["external_factors_current"], test_data["external_factors_previous"])
            
            results[scenario_name] = {
                "input_trend": test_data["sales_history"][-3:],  # Last 3 values
                "gru_prediction": result["gru_prediction"],
                "xgboost_adjustment": result["xgboost_adjustment"],
                "final_prediction": result["final_prediction"],
                "confidence": result["confidence_score"],
                "adjustment_ratio": result["ensemble_breakdown"]["adjustment_ratio"]
            }
            
            print(f"‚úÖ {scenario_name}: GRU={result['gru_prediction']:,.0f}, XGB={result['xgboost_adjustment']:,.0f}, Final={result['final_prediction']:,.0f}")
            
        except Exception as e:
            results[scenario_name] = {"error": str(e)}
            print(f"‚ùå {scenario_name}: {str(e)}")
    
    return {
        "ensemble_tests": results,
        "note": "Test lu·ªìng ho·∫°t ƒë·ªông ensemble v·ªõi c√°c scenarios kh√°c nhau",
        "workflow": "GRU ‚Üí XGBoost ‚Üí Ensemble Final"
    }

if __name__ == "__main__":
    import uvicorn
    print("üöÄ Starting Ensemble GRU + XGBoost Sales Prediction API...")
    print("üìä Models: GRU (Base) + XGBoost (Adjustment)")
    print("üéØ Endpoint: http://localhost:8000")
    print("üìñ Documentation: http://localhost:8000/docs")
    print("üß™ Test endpoint: http://localhost:8000/test-ensemble")
    uvicorn.run(app, host="0.0.0.0", port=8000)
