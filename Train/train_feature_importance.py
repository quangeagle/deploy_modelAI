# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# from xgboost import XGBRegressor, plot_importance
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import r2_score, mean_squared_error
# from sklearn.preprocessing import StandardScaler

# # 1. Load dataset
# df = pd.read_csv('walmart_processed_by_week.csv')  # ƒê·ªïi t√™n file n·∫øu kh√°c

# # 2. X·ª≠ l√Ω c·ªôt ng√†y
# df['Date'] = pd.to_datetime(df['Date'])

# # 3. T·∫°o ƒë·∫∑c tr∆∞ng tu·∫ßn Black Friday (tu·∫ßn 47 ho·∫∑c 48)
# df['Is_BlackFriday_Week'] = df['WeekOfYear'].apply(lambda x: 1 if x in [47, 48] else 0)

# # 4. Ch·ªçn ƒë·∫∑c tr∆∞ng v√† target
# features = [
#     'Holiday_Flag', 'Temperature', 'Fuel_Price',
#     'CPI', 'Unemployment',
#     'Week_Index', 'WeekOfYear', 'Month', 'Year', 'Is_BlackFriday_Week'
# ]
# target = 'Weekly_Sales'

# X = df[features]
# y = df[target]

# # 5. Chu·∫©n h√≥a d·ªØ li·ªáu
# scaler = StandardScaler()
# X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=features)

# # 6. Chia d·ªØ li·ªáu train/test
# X_train, X_test, y_train, y_test = train_test_split(
#     X_scaled, y, test_size=0.2, random_state=42
# )

# # 7. Train m√¥ h√¨nh XGBoost
# model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
# model.fit(X_train, y_train)

# # 8. D·ª± ƒëo√°n v√† ƒë√°nh gi√°
# y_pred = model.predict(X_test)
# r2 = r2_score(y_test, y_pred)
# rmse = np.sqrt(mean_squared_error(y_test, y_pred))
# print(f'‚úÖ R2 Score: {r2:.4f}')
# print(f'üìâ RMSE: {rmse:.2f}')

# # 9. Ph√¢n t√≠ch t·∫ßm quan tr·ªçng ƒë·∫∑c tr∆∞ng
# plt.figure(figsize=(10, 6))
# plot_importance(model, importance_type='gain', max_num_features=10)
# plt.title("üéØ Feature Importance (XGBoost)")
# plt.tight_layout()
# plt.show()

# # 10. T·∫°o b·∫£ng so s√°nh d·ª± ƒëo√°n trong tu·∫ßn Black Friday
# df['Predicted'] = model.predict(scaler.transform(X))
# black_friday_df = df[df['Is_BlackFriday_Week'] == 1]
# print("\nüìà Doanh s·ªë d·ª± ƒëo√°n trong tu·∫ßn Black Friday:")
# print(black_friday_df[['Date', 'Weekly_Sales', 'Predicted']].sort_values('Date'))
# plt.figure(figsize=(12, 5))
# sns.boxplot(x='WeekOfYear', y='Weekly_Sales', data=df)
# plt.title('Doanh s·ªë theo tu·∫ßn trong nƒÉm')
# plt.xticks(rotation=90)
# plt.tight_layout()
# plt.show()
# plt.figure(figsize=(10, 5))
# sns.boxplot(x='Month', y='Weekly_Sales', data=df)
# plt.title('Doanh s·ªë theo th√°ng')
# plt.tight_layout()
# plt.show()
# sns.boxplot(x='Month', y='Weekly_Sales', data=df)
# plt.title('Doanh s·ªë theo th√°ng')
# plt.show()

# # Doanh s·ªë theo tu·∫ßn trong nƒÉm
# sns.boxplot(x='WeekOfYear', y='Weekly_Sales', data=df)
# plt.title('Doanh s·ªë theo tu·∫ßn trong nƒÉm')
# plt.xticks(rotation=90)
# plt.show()



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from xgboost import XGBRegressor, plot_importance
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

# 1. Load dataset
df = pd.read_csv('walmart_processed_by_week.csv')
df['Date'] = pd.to_datetime(df['Date'])
df['Is_BlackFriday_Week'] = df['WeekOfYear'].apply(lambda x: 1 if x in [47, 48] else 0)

# 2. Ch·ªçn ƒë·∫∑c tr∆∞ng
features = [
    'Holiday_Flag', 'Temperature', 'Fuel_Price',
    'CPI', 'Unemployment',
    'Week_Index', 'WeekOfYear', 'Month', 'Year', 'Is_BlackFriday_Week'
]
target = 'Weekly_Sales'
X = df[features]
y = df[target]

# 3. Chu·∫©n h√≥a
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=features)

# Chia train/test
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# ===========================
# 4. Train XGBoost
# ===========================
model_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
model_xgb.fit(X_train, y_train)
y_pred_xgb = model_xgb.predict(X_test)

r2_xgb = r2_score(y_test, y_pred_xgb)
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))
print(f'üìò XGBoost R¬≤: {r2_xgb:.4f}, RMSE: {rmse_xgb:.2f}')

# ===========================
# 5. Train GRU (PyTorch)
# ===========================
class GRUNet(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(GRUNet, self).__init__()
        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.gru(x)
        return self.fc(out[:, -1, :])

# Chu·∫©n b·ªã d·ªØ li·ªáu GRU
def to_tensor(x): return torch.tensor(x, dtype=torch.float32)

X_train_seq = to_tensor(X_train.values).unsqueeze(1)
X_test_seq = to_tensor(X_test.values).unsqueeze(1)
y_train_tensor = to_tensor(y_train.values).unsqueeze(1)
y_test_tensor = to_tensor(y_test.values).unsqueeze(1)

train_loader = DataLoader(TensorDataset(X_train_seq, y_train_tensor), batch_size=64, shuffle=True)

# Kh·ªüi t·∫°o m√¥ h√¨nh
gru = GRUNet(input_size=X_train.shape[1], hidden_size=64, output_size=1)
optimizer = torch.optim.Adam(gru.parameters(), lr=0.001)
loss_fn = nn.MSELoss()

# Train GRU
for epoch in range(50):
    for xb, yb in train_loader:
        pred = gru(xb)
        loss = loss_fn(pred, yb)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

# D·ª± ƒëo√°n GRU
y_pred_gru = gru(X_test_seq).detach().numpy().flatten()
r2_gru = r2_score(y_test, y_pred_gru)
rmse_gru = np.sqrt(mean_squared_error(y_test, y_pred_gru))
print(f'üìï GRU R¬≤: {r2_gru:.4f}, RMSE: {rmse_gru:.2f}')

# ===========================
# 6. So s√°nh k·∫øt qu·∫£
# ===========================
plt.bar(['XGBoost', 'GRU'], [r2_xgb, r2_gru], color=['skyblue', 'salmon'])
plt.title('So s√°nh R¬≤ XGBoost vs GRU')
plt.ylabel('R¬≤ Score')
plt.ylim(0, 1)
plt.show()

# ===========================
# 7. Ph√¢n t√≠ch chi ti·∫øt XGBoost + bi·ªÉu ƒë·ªì tu·∫ßn/th√°ng
# ===========================
plt.figure(figsize=(10, 6))
plot_importance(model_xgb, importance_type='gain', max_num_features=10)
plt.title("üéØ Feature Importance (XGBoost)")
plt.tight_layout()
plt.show()

df['Predicted_XGB'] = model_xgb.predict(scaler.transform(X))
df['Predicted_GRU'] = gru(torch.tensor(scaler.transform(X), dtype=torch.float32).unsqueeze(1)).detach().numpy()

black_friday_df = df[df['Is_BlackFriday_Week'] == 1]
print("\nüìà Doanh s·ªë d·ª± ƒëo√°n trong tu·∫ßn Black Friday:")
print(black_friday_df[['Date', 'Weekly_Sales', 'Predicted_XGB', 'Predicted_GRU']].sort_values('Date'))

# Boxplot tu·∫ßn & th√°ng
plt.figure(figsize=(12, 5))
sns.boxplot(x='WeekOfYear', y='Weekly_Sales', data=df)
plt.title('Doanh s·ªë theo tu·∫ßn trong nƒÉm')
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 5))
sns.boxplot(x='Month', y='Weekly_Sales', data=df)
plt.title('Doanh s·ªë theo th√°ng')
plt.tight_layout()
plt.show()
